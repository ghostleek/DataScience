{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_SECRETS_FILE = \"client_secret.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/youtube.force-ssl']\n",
    "API_SERVICE_NAME = 'youtube'\n",
    "API_VERSION = 'v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import google.oauth2.credentials\n",
    " \n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    " \n",
    "...\n",
    "...\n",
    " \n",
    "def get_authenticated_service():\n",
    "    credentials = None\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            credentials = pickle.load(token)\n",
    "    #  Check if the credentials are invalid or do not exist\n",
    "    if not credentials or not credentials.valid:\n",
    "        # Check if the credentials have expired\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            credentials.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                CLIENT_SECRETS_FILE, SCOPES)\n",
    "            credentials = flow.run_console()\n",
    " \n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(credentials, token)\n",
    " \n",
    "    return build(API_SERVICE_NAME, API_VERSION, credentials = credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=864205785847-0uqbed7rqqd3telgp549trdtu77gkpfs.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.force-ssl&state=XubME0lvFCQL08D4ug7MzByjKvl5Jo&prompt=consent&access_type=offline\n",
      "Enter the authorization code: 4/tgFiHT_9LwAc7hFIOYaPwetNvfsm_vJ8djOkNOZEeX8BsS-IgjcVMG8\n",
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=864205785847-0uqbed7rqqd3telgp549trdtu77gkpfs.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.force-ssl&state=kJqaIqhu8eHnu0BQvmwgQwtoiOQ618&prompt=consent&access_type=offline\n",
      "Enter the authorization code: 4/tgEjjBnmSeWtUK_X7D3FkT0GeSlB0MbFFSb9gXnbjzwLCrbHpaIzic8\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # When running locally, disable OAuthlib's HTTPs verification. When\n",
    "    # running in production *do not* leave this option enabled.\n",
    "    os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "    service = get_authenticated_service()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # When running locally, disable OAuthlib's HTTPs verification. When\n",
    "    # running in production *do not* leave this option enabled.\n",
    "    os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "    service = get_authenticated_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a keyword: Tesla cybertruck\n",
      "WATCH LIVE! Elon Musk presents the new Tesla Cybertruck Launch - SwvDOdBHYBw\n",
      "Tesla Cybertruck live test ride - KoutN_Ezs8w\n",
      "Cybertruck tesla - Teslatruck - electrictruck - SYnIg2qk_xc\n",
      "Tesla Cyber Truck Unveil | 1080p60 HD | Livestream Replay - rDQ3UnPA_E8\n",
      "A.I &amp; TESLA CYBERTRUCKS - THE FUTURE IS HERE - ipU8wlAM5w0\n"
     ]
    }
   ],
   "source": [
    "#this only returns the first page of results\n",
    "def search_videos_by_keyword(service, **kwargs):\n",
    "    results = service.search().list(**kwargs).execute()\n",
    "    for item in results['items']:\n",
    "        print('%s - %s' % (item['snippet']['title'], item['id']['videoId']))\n",
    " \n",
    " \n",
    "keyword = input('Enter a keyword: ')\n",
    "search_videos_by_keyword(service, q=keyword, part='id,snippet', eventType='completed', type='video')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a keyword: Tesla cybertruck\n",
      "WATCH LIVE! Elon Musk presents the new Tesla Cybertruck Launch - SwvDOdBHYBw\n",
      "Tesla Cybertruck live test ride - KoutN_Ezs8w\n",
      "Cybertruck tesla - Teslatruck - electrictruck - SYnIg2qk_xc\n",
      "Tesla Cyber Truck Unveil | 1080p60 HD | Livestream Replay - rDQ3UnPA_E8\n",
      "A.I &amp; TESLA CYBERTRUCKS - THE FUTURE IS HERE - ipU8wlAM5w0\n",
      "My thoughts on the Tesla cybertruck - ckWO2zFk66E\n",
      "Tesla CyberTruck Review / Storm Chasing Beast for 2021 - Q1Q9PPRK_hQ\n",
      "The Tesla CyberWHAT THE??? CYBERTRUCK - BEfbAXy81RU\n",
      "COPPA, Tesla Cybertruck, and Disney+ The White Hatter Live Nov 24 - qb46mKJ0AHg\n",
      "ðŸ”´Tesla Truck Unveil Event LIVE REWINDðŸ”´ - gEwtrXGOW_o\n"
     ]
    }
   ],
   "source": [
    "#get up to 3 or more pages of results\n",
    "#in this case I specified 5 pages\n",
    "def get_videos(service, **kwargs):\n",
    "    final_results = []\n",
    "    results = service.search().list(**kwargs).execute()\n",
    " \n",
    "    i = 0\n",
    "    max_pages = 2\n",
    "    while results and i < max_pages:\n",
    "        final_results.extend(results['items'])\n",
    " \n",
    "        # Check if another page exists\n",
    "        if 'nextPageToken' in results:\n",
    "            kwargs['pageToken'] = results['nextPageToken']\n",
    "            results = service.search().list(**kwargs).execute()\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    " \n",
    "    return final_results\n",
    " \n",
    "def search_videos_by_keyword(service, **kwargs):\n",
    "    results = get_videos(service, **kwargs)\n",
    "    for item in results:\n",
    "        print('%s - %s' % (item['snippet']['title'], item['id']['videoId']))\n",
    " \n",
    " \n",
    "keyword = input('Enter a keyword: ')\n",
    "search_videos_by_keyword(service, q=keyword, part='id,snippet', eventType='completed', type='video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(service, **kwargs):\n",
    "    comments = []\n",
    "    results = service.commentThreads().list(**kwargs).execute()\n",
    " \n",
    "    while results:\n",
    "        for item in results['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)\n",
    " \n",
    "        # Check if another page exists\n",
    "        if 'nextPageToken' in results:\n",
    "            kwargs['pageToken'] = results['nextPageToken']\n",
    "            results = service.commentThreads().list(**kwargs).execute()\n",
    "        else:\n",
    "            break\n",
    " \n",
    "    return comments\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    " \n",
    "def write_to_csv(comments):\n",
    "    with open('comments.csv', 'w') as comments_file:\n",
    "        comments_writer = csv.writer(comments_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        comments_writer.writerow(['Video ID', 'Title', 'Comment'])\n",
    "        for row in comments:\n",
    "            comments_writer.writerow(list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(service, **kwargs):\n",
    "    final_results = []\n",
    "    results = service.search().list(**kwargs).execute()\n",
    " \n",
    "    i = 0\n",
    "    max_pages = 3\n",
    "    while results and i < max_pages:\n",
    "        final_results.extend(results['items'])\n",
    " \n",
    "        # Check if another page exists\n",
    "        if 'nextPageToken' in results:\n",
    "            kwargs['pageToken'] = results['nextPageToken']\n",
    "            results = service.search().list(**kwargs).execute()\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    " \n",
    "    return final_results\n",
    " \n",
    " \n",
    "def search_videos_by_keyword(service, **kwargs):\n",
    "    results = get_videos(service, **kwargs)\n",
    "    final_result = []\n",
    "    for item in results:\n",
    "        title = item['snippet']['title']\n",
    "        video_id = item['id']['videoId']\n",
    "        comments = get_video_comments(service, part='snippet', videoId=video_id, textFormat='plainText')\n",
    "        # make a tuple consisting of the video id, title, comment and add the result to \n",
    "        # the final list\n",
    "        final_result.extend([(video_id, title, comment) for comment in comments]) \n",
    " \n",
    "    write_to_csv(final_result)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
